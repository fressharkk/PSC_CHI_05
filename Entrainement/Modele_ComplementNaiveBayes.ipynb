{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a364e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importations utiles liés à la gestion des données\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tq\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c9f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_from_fp_db(fp_db):\n",
    "    '''\n",
    "    Cette fonction permet de recréer le fingerprint de taille 2048\n",
    "    à partir du fingerprint codé en mémoire\n",
    "    '''\n",
    "    res = np.zeros(2048)\n",
    "    #On initialise un array de 2048 zéros\n",
    "    list_idx = fp_db.split(\" \")\n",
    "    #On récupère tous les indices non nuls du fingerprint\n",
    "    for el in list_idx[:-1]:\n",
    "        lfp = el.split(\"-\")\n",
    "        n = len(lfp)\n",
    "        #En fonction des cas, on complète avec la bonne valeur\n",
    "        if n == 1:\n",
    "            res[int(lfp[0])] = 1\n",
    "        elif n==2:\n",
    "            res[int(lfp[0])] = int(lfp[-1])\n",
    "        else:\n",
    "            res[int(lfp[0])] = -int(lfp[-1])\n",
    "    return res\n",
    "\n",
    "def input_model_from_db(base_fp):\n",
    "    '''\n",
    "    Cette fonction renvoie un array de fingerprint à partir d'un dataset contenant des\n",
    "    fingerprints sous forme \"codée\"\n",
    "    '''\n",
    "    #On sépare fingerprint de réactions et fingerprints du produit\n",
    "    prod_fp_db,rxn_fp_db = base_fp[\"Product_Fingerprint\"],base_fp[\"Reaction_Fingerprint\"]\n",
    "    prod_fp,rxn_fp = [],[]\n",
    "    p_bar = tq.tqdm(total=base_fp.shape[0])\n",
    "    for i in range(base_fp.shape[0]):\n",
    "        #On essaie de récupérer le fingerprint associé à la ligne i\n",
    "        try:\n",
    "            p_bar.update(1)\n",
    "            rxn_fp.append(fp_from_fp_db(rxn_fp_db.iloc[i]))\n",
    "            prod_fp.append(fp_from_fp_db(prod_fp_db.iloc[i]))\n",
    "        except:\n",
    "            continue\n",
    "    return np.array(prod_fp), np.array(rxn_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ca46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_fp_false = \"C:/Users/Yassine/Desktop/PSC/PSC_final/Data/False_reactions/Reactions_Fingerprint_False.csv\"\n",
    "fname_fp_true = \"C:/Users/Yassine/Desktop/PSC/PSC_final/Data/True_reactions/Reactions_Fingerprint_True.csv\"\n",
    "fname_groups_false = \"C:/Users/Yassine/Desktop/PSC/PSC_final/Data/False_reactions/False_reac_groups.csv\"\n",
    "fname_groups_true = \"C:/Users/Yassine/Desktop/PSC/PSC_final/Data/True_reactions/True_reac_groups.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282fff30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#On récupère les bases de données associées aux noms des fichiers\n",
    "data_fp_false = pd.read_csv(fname_fp_false)\n",
    "data_fp_true = pd.read_csv(fname_fp_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d8ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère la taille des données\n",
    "size_true = data_fp_true.shape[0]\n",
    "size_false = data_fp_false.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c72ed9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8221913ffa646cfbb13cf362f567513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#On convertit les données en fingerprint \n",
    "#On tronque pour ne pas saturer la RAM\n",
    "size_percentage = 0.1\n",
    "#On récupère les produits et les réactions correspondantes sous forme de fingerprint\n",
    "p1,p2 = input_model_from_db(data_fp_true[:int(size_true*size_percentage)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190da281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf777ce7e5424e60b9d759afc7765e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#On récupère les produits et les réactions correspondantes sous forme de fingerprint pour la base de données fausses\n",
    "#Dans le but de ne pas induire un biais, on garde la même proportion de données vraies et fausses\n",
    "#Nous avons essayé de shuffle les données avant et d'entraîner notre modèle mais cela n'a pas donné de \n",
    "#différences notables \n",
    "#Nous avons donc gardé la version la plus simple\n",
    "p3,p4 = input_model_from_db(data_fp_false[:int(size_true*size_percentage)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a73e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array des Fingerprints des Produits liés aux Vraies Reactions et Fausses Reactions\n",
    "prod_fp = np.concatenate((p1, p3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e9cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array des Fingerprints des Réactions liés aux Vraies Reactions et Fausses Reactions\n",
    "rxn_fp = np.concatenate((p2,p4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46c371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels : 1 pour les vraies réactions, 0 pour les fausses\n",
    "labels = np.array([1]*p1.shape[0]+[0]*p3.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3efae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PARAMETRES : proportion d'entraînement\n",
    "train_prop = 0.9\n",
    "test_prop  = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79b73ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On divise les données de façon aléatoire : on utilise le random_state 42 pour avoir des résultats reproductibles\n",
    "prd_fp_train, prd_fp_test, rxn_fp_train, rxn_fp_test, labels_train, labels_test = train_test_split(prod_fp, rxn_fp, labels, train_size = train_prop, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b73f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On écrit la data en input sous la forme désirée\n",
    "data_input = [np.concatenate((rxn_fp_train[i], prd_fp_train[i])) for i in range(rxn_fp_train.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0f6e4",
   "metadata": {},
   "source": [
    "## Entrainement du Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a52c0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNB = ComplementNB() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae6fb3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNB.fit(data_input, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ccbbe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On sauve le modèle \n",
    "filename = 'Complement_Bayesian_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aizynth-env",
   "language": "python",
   "name": "aizynth-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
