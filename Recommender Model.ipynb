{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4b00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa1d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73603152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d624e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c8fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e7e7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "89103166",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We start by purifying our databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "983191ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_json(\"uspto-templates.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "647b67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = pd.read_json(\"uspto-reactions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d6f0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = file['reaction_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7d9d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = file2['_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7da9331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_not_in_templates = list(set(l2)-set(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "90205d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = file['reaction_smarts'].to_numpy()[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "470488f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file['reaction_smarts'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0469327f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25bc167cb2344b6a87430cfb6dee46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1800000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows_with_nan = []\n",
    "pb = tqdm.tqdm(total=1800000)\n",
    "for index, row in file.iterrows():\n",
    "    pb.update(1)\n",
    "    is_nan_series = row.isnull()\n",
    "    if is_nan_series.any():\n",
    "        rows_with_nan.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fd04a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reac_id_nan = []\n",
    "for val in rows_with_nan:\n",
    "    reac_id_nan.append(file.iloc[val,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6c91e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = []\n",
    "for val in reac_id_nan:\n",
    "    to_delete.append(df.index[df[\"_id\"]==val].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9881aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = [i for f in to_delete for i in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6a210fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(to_delete, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c461ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.drop(rows_with_nan, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "50bb0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.to_csv(\"Purified_templates.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2769691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Purified_reactions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d5514eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4725abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for val in ids_not_in_templates:\n",
    "    x.append(df.index[df[\"_id\"] == val].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "46e08885",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_delete = [i for f in x for i in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48d181c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(ids_to_delete, axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d0666b8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[108905, 280174, 869040, 869041, 869042, 1661986] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-7b865f844fd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows_with_nan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\aizynth-env\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aizynth-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4954\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4955\u001b[0m         \"\"\"\n\u001b[1;32m-> 4956\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4957\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4958\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aizynth-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4277\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4278\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4279\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aizynth-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4321\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4322\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4323\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4324\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aizynth-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6643\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6644\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6645\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6646\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[108905, 280174, 869040, 869041, 869042, 1661986] not found in axis'"
     ]
    }
   ],
   "source": [
    "df.drop(rows_with_nan, axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f193e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6531bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0123321",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data_templates.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdb02d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file.drop_duplicates(subset=\"reaction_smarts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "326643de",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = data['reaction_smarts'].to_list()\n",
    "my_map = dict(list(enumerate(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8611f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = {v: k for k, v in my_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4faee1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_from_fp_db(fp_db):\n",
    "    res = np.zeros(2048)\n",
    "    list_idx = fp_db.split(\" \")\n",
    "    for el in list_idx[:-1]:\n",
    "        lfp = el.split(\"-\")\n",
    "        n = len(lfp)\n",
    "        if n == 1:\n",
    "            res[int(lfp[0])] = 1\n",
    "        elif n==2:\n",
    "            res[int(lfp[0])] = int(lfp[-1])\n",
    "        else:\n",
    "            res[int(lfp[0])] = -int(lfp[-1])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26837a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=32, n_channels=1,\n",
    "                 n_classes=10, shuffle=True, _filename_fp=\"\", _filename_templates = \"\", _filename_reactions=\"\"):\n",
    "        'Initialization'\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.list_IDs = list_IDs\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.filename_fp = _filename_fp\n",
    "        self.filename_templates = _filename_templates\n",
    "        self.filename_reactions = _filename_reactions\n",
    "        \n",
    "        self.data_fp = pd.read_csv(_filename_fp)\n",
    "        self.data_templates = pd.read_csv(_filename_templates)\n",
    "        self.data_reactions = pd.read_csv(_filename_reactions)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, 2048))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = fp_from_fp_db(self.data_fp.iloc[i,1]-self.data_fp.iloc[i,2])\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.data_reactions.iloc[i,0]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb594ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "    \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load('data/' + ID + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ba199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from my_classes import DataGenerator\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (32,32,32),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 6,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "partition = # IDs\n",
    "labels = # Labels\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "# Design model\n",
    "model = Sequential()\n",
    "[...] # Architecture\n",
    "model.compile()\n",
    "\n",
    "# Train model on dataset\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11112f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720033.6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sys.getsizeof(np.zeros(300000))/1000*300000)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e3406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(2048,),activation=\"elu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(n, activation=\"softmax\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aizynth-env",
   "language": "python",
   "name": "aizynth-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
